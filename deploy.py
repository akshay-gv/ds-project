# -*- coding: utf-8 -*-
"""deploy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iXnu2n875U0CtYgK_9z1DkFL5HlvGSnM
"""

import pickle
import nltk
import string
import os
import numpy as np
import pandas as pd
import streamlit as st
from nltk.corpus import stopwords
import requests
from nltk.stem.wordnet import WordNetLemmatizer
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('omw-1.4')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

model_URL='https://intro-ds-gv.s3.amazonaws.com/GBC.sav'
vect_url ='https://intro-ds-gv.s3.amazonaws.com/TFIDF_Vect.pkl'

response = requests.get(model_URL)
open('GBC.sav', "wb").write(response.content)

response = requests.get(vect_url)
open('TFIDF_Vect.pkl', "wb").write(response.content)

model = pickle.load(open('GBC.sav','rb'))
TFIDF_Vect = pickle.load(open('TFIDF_Vect.pkl','rb'))

os.remove('GBC.sav')
os.remove('TFIDF_Vect.pkl')

sw_lst = stopwords.words('english') + list(string.punctuation) + ['--', 'xxxx',"''", '""', '...', '``']
def process_txt(txt):
    tokens = nltk.word_tokenize(txt)
    sw_rmd = [token.lower() for token in tokens if token.lower() not in sw_lst]
    sw_punc_num_rmd = [w for w in sw_rmd if w.isalpha()]
    return sw_punc_num_rmd 

def join_complaints(lst):
    words = ''
    for word in lst:
        words += word + ' '
    return words.strip()

# lemmatization of the words
lzm = WordNetLemmatizer()

def grouping(lst):
    lst = [i for i in lst if i is not np.nan]
    words = []
    for i, word in enumerate(lst):
        words.append(lzm.lemmatize(word))
    joined_complaint = join_complaints(words)
    return joined_complaint

def predict(narrative):
  comp_processed = process_txt(narrative)
  cmpl = grouping(comp_processed)
  prod_match_dict ={0:'debt_collection', 1:'credit_card', 2:'credit_reporting',3:'retail_banking', 4:'mortgages_and_loans'}
  y = model.predict(TFIDF_Vect.transform([cmpl]))
  return prod_match_dict.get(y[0])

def main():
    st.title("Complaints Tagger")
    html_temp = """
    <div style="background-color:black;padding:10px">
    <h4 style="color:white;text-align:center;">API to tag complaints to respective departments.</h4>
    </div>
    """
    st.markdown(html_temp,unsafe_allow_html=True)
    complaint = st.text_input("Enter the complaint below:","")
    result=""
    if st.button("Predict"):
        result=predict(complaint)
        st.success('This complaint must be diverted to {} department'.format(result))
if __name__=='__main__':
    main()